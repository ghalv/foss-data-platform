# FOSS Data Platform

A modern, open-source data platform built with best-in-class FOSS tools for reliable, scalable data engineering.

## Current Architecture Overview

```
ğŸ¯ LAKEHOUSE ARCHITECTURE - CURRENT STATE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                 WORKING PIPELINE                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                        STAVANGER PARKING PIPELINE                               â”‚    â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚   â”‚   Data Source   â”‚  â”‚   dbt Pipeline  â”‚  â”‚  Iceberg Tables  â”‚  â”‚  Dashboard  â”‚ â”‚    â”‚
â”‚  â”‚   â”‚   (REST API)    â”‚  â”‚   (Transform)   â”‚  â”‚   (Storage)      â”‚  â”‚   (Web UI)  â”‚ â”‚    â”‚
â”‚  â”‚   â”‚                 â”‚  â”‚   â”œâ”€ Bronze     â”‚  â”‚   â”œâ”€ ACID        â”‚  â”‚   â”œâ”€ Mgmt   â”‚ â”‚    â”‚
â”‚  â”‚   â”‚                 â”‚  â”‚   â”œâ”€ Silver     â”‚  â”‚   â”œâ”€ Time Travel â”‚  â”‚   â”œâ”€ Browse â”‚ â”‚    â”‚
â”‚  â”‚   â”‚                 â”‚  â”‚   â””â”€ Gold       â”‚  â”‚   â””â”€ Schema Evol â”‚  â”‚   â””â”€ Health â”‚ â”‚    â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              PLATFORM INFRASTRUCTURE                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Flask Web App â”‚  â”‚   Docker Compose â”‚  â”‚   Python Scripts â”‚  â”‚   Shell Scripts â”‚    â”‚
â”‚  â”‚   (Dashboard)   â”‚  â”‚  (Orchestration) â”‚  â”‚   (Automation)   â”‚  â”‚   (Management)  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Trino         â”‚  â”‚     MinIO       â”‚  â”‚    Dagster      â”‚  â”‚    Portainer    â”‚    â”‚
â”‚  â”‚  (Configured)   â”‚  â”‚  (Configured)   â”‚  â”‚  (Configured)   â”‚  â”‚  (Configured)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Status

**ğŸŸ¢ ACTIVE COMPONENTS:**
- **dbt Pipeline**: SQL-based data transformations with medallion architecture
- **Apache Iceberg**: Table format for lakehouse with ACID transactions
- **Flask Dashboard**: Web interface for pipeline management and data browsing
- **Docker Compose**: Container orchestration for all services

**ğŸŸ¡ CONFIGURED BUT NOT INTEGRATED:**
- **Trino**: Distributed SQL query engine (ready for integration)
- **MinIO**: S3-compatible object storage (ready for integration)
- **Dagster**: Pipeline orchestration (configured but dbt handles current orchestration)

**ğŸ”´ FUTURE ENHANCEMENTS:**
- Multi-pipeline support
- Advanced analytics with Trino
- Object storage integration with MinIO
- Enhanced monitoring and alerting

## Technology Stack

### ğŸŸ¢ ACTIVE COMPONENTS (Currently Working)
- **Data Transformation**: dbt (SQL-based transformations with medallion architecture)
- **Storage Layer**: Apache Iceberg (ACID transactions, time travel, schema evolution)
- **Web Dashboard**: Flask + Bootstrap (Pipeline management, data browsing, health monitoring)
- **Container Orchestration**: Docker Compose (Service orchestration and deployment)

### ğŸŸ¡ CONFIGURED COMPONENTS (Ready for Integration)
- **Query Engine**: Trino (Distributed SQL queries - configured in docker-compose.yml)
- **Object Storage**: MinIO (S3-compatible storage - configured in docker-compose.yml)
- **Pipeline Orchestration**: Dagster (Job scheduling - configured but not actively used)
- **Container Management**: Portainer (Docker management - configured in docker-compose.yml)

### ğŸ”§ DEVELOPMENT & MANAGEMENT
- **Python Scripts**: Automation and utility scripts in `scripts/` and `tools/scripts/`
- **Shell Scripts**: Service management scripts in `scripts/` and `infrastructure/`
- **Version Control**: Git for code management
- **Documentation**: Markdown-based docs in `docs/` directory

## Quick Start

### Prerequisites
- Docker and Docker Compose installed
- Python 3.11+ (for local development)
- Git for version control

### ğŸš€ Start the Platform
```bash
# Clone the repository
git clone <repository-url>
cd foss-dataplatform

# Start all services with Docker Compose
docker-compose up -d

# Start the dashboard (alternative method)
./scripts/start_dashboard.sh
```

### ğŸŒ Access the Platform
Once started, access these services:

#### ğŸŸ¢ ACTIVE SERVICES:
- **Main Dashboard**: http://localhost:5000 (Pipeline management & data browsing)
- **Pipeline Management**: http://localhost:5000/pipeline-management
- **Data Browser**: http://localhost:5000/data-browser
- **Health Check**: http://localhost:5000/health
- **About Page**: http://localhost:5000/about

#### ğŸŸ¡ CONFIGURED SERVICES (May require additional setup):
- **Trino Query Engine**: http://localhost:8080 (SQL analytics)
- **MinIO Object Storage**: http://localhost:9000 (S3-compatible storage)
- **Portainer**: http://localhost:9001 (Container management)
- **Dagster**: http://localhost:3000 (Pipeline orchestration UI)

### ğŸ“Š Current Pipeline
The platform comes with a working **Stavanger Parking Pipeline** that:
- Ingests real-time parking data from Stavanger municipality API
- Transforms data using dbt with medallion architecture (Bronze â†’ Silver â†’ Gold)
- Stores data in Apache Iceberg tables with ACID transactions
- Provides web-based monitoring and data browsing

### ğŸ”§ Development Workflow
```bash
# View pipeline data
# Go to: http://localhost:5000/pipeline-management

# Browse processed data
# Go to: http://localhost:5000/data-browser

# Check system health
# Go to: http://localhost:5000/health
```

## ğŸ“ Project Structure & File Locations

```
foss-dataplatform/
â”œâ”€â”€ ğŸ“Š pipelines/                          # ğŸ¯ WHERE PIPELINES RESIDE
â”‚   â””â”€â”€ stavanger_parking/                 # Current working pipeline
â”‚       â”œâ”€â”€ dbt/                           # ğŸ—ï¸ WHERE TRANSFORMATIONS RESIDE
â”‚       â”‚   â”œâ”€â”€ models/                    # dbt SQL models (Bronze/Silver/Gold)
â”‚       â”‚   â”‚   â”œâ”€â”€ bronze/                # Raw data models
â”‚       â”‚   â”‚   â”œâ”€â”€ silver/                # Cleaned data models
â”‚       â”‚   â”‚   â””â”€â”€ gold/                  # Analytics-ready models
â”‚       â”‚   â”œâ”€â”€ tests/                     # Data quality tests
â”‚       â”‚   â”œâ”€â”€ macros/                    # Reusable SQL macros
â”‚       â”‚   â”œâ”€â”€ seeds/                     # Static data files
â”‚       â”‚   â””â”€â”€ dbt_project.yml            # dbt configuration
â”‚       â”œâ”€â”€ data/                          # ğŸ’¾ WHERE PIPELINE DATA RESIDES
â”‚       â”‚   â”œâ”€â”€ raw/                       # Raw ingested data
â”‚       â”‚   â”œâ”€â”€ staging/                   # Cleaned/transformed data
â”‚       â”‚   â””â”€â”€ processed/                 # Final processed datasets
â”‚       â”œâ”€â”€ docs/                          # Pipeline documentation
â”‚       â””â”€â”€ scripts/                       # Pipeline-specific scripts
â”‚
â”œâ”€â”€ ğŸ—ï¸ platform/                           # Platform infrastructure (future use)
â”‚   â”œâ”€â”€ governance/                        # Data governance (placeholder)
â”‚   â”œâ”€â”€ monitoring/                        # Monitoring configs (placeholder)
â”‚   â””â”€â”€ security/                          # Security policies (placeholder)
â”‚
â”œâ”€â”€ ğŸ”§ scripts/                            # âš™ï¸ WHERE CORE SCRIPTS RESIDE
â”‚   â”œâ”€â”€ start_dashboard.sh                 # Dashboard startup script
â”‚   â”œâ”€â”€ monitor_dashboard.sh               # Dashboard monitoring script
â”‚   â””â”€â”€ [other automation scripts]         # Service management scripts
â”‚
â”œâ”€â”€ ğŸ“š docs/                               # ğŸ“– WHERE DOCUMENTATION RESIDES
â”‚   â”œâ”€â”€ README.md                          # This main README
â”‚   â”œâ”€â”€ DASHBOARD_README.md                # Dashboard usage guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md                    # System architecture docs
â”‚   â”œâ”€â”€ PIPELINE_MANAGEMENT_GUIDE.md       # Pipeline development guide
â”‚   â””â”€â”€ [other documentation files]        # Platform documentation
â”‚
â”œâ”€â”€ ğŸŒ dashboard/                          # ğŸ›ï¸ WHERE WEB DASHBOARD RESIDES
â”‚   â”œâ”€â”€ app.py                             # Flask application (main core)
â”‚   â”œâ”€â”€ templates/                         # HTML templates
â”‚   â”‚   â”œâ”€â”€ dashboard.html                 # Main dashboard page
â”‚   â”‚   â”œâ”€â”€ pipeline_management.html       # Pipeline management
â”‚   â”‚   â”œâ”€â”€ data_browser.html              # Data browsing interface
â”‚   â”‚   â”œâ”€â”€ about.html                     # About page
â”‚   â”‚   â””â”€â”€ [other HTML templates]         # UI templates
â”‚   â””â”€â”€ static/                            # CSS/JS/images (if added later)
â”‚
â”œâ”€â”€ âš™ï¸ infrastructure/                     # ğŸ—ï¸ WHERE INFRA CONFIGS RESIDE
â”‚   â”œâ”€â”€ foss-dashboard.service             # Systemd service for dashboard
â”‚   â””â”€â”€ [other infrastructure files]       # Deployment configurations
â”‚
â”œâ”€â”€ ğŸ› ï¸ tools/                              # ğŸ”¨ WHERE DEVELOPMENT TOOLS RESIDE
â”‚   â”œâ”€â”€ scripts/                           # Additional utility scripts
â”‚   â”‚   â”œâ”€â”€ qa_test_suite.py               # Quality assurance tests
â”‚   â”‚   â”œâ”€â”€ service_validation_suite.py    # Service validation
â”‚   â”‚   â””â”€â”€ [other development scripts]    # Development utilities
â”‚   â”œâ”€â”€ cli/                               # Command-line tools
â”‚   â””â”€â”€ templates/                         # Code generation templates
â”‚
â”œâ”€â”€ ğŸ“¦ docker-compose.yml                  # ğŸ³ WHERE CONTAINER CONFIGS RESIDE
â”œâ”€â”€ ğŸ“‹ requirements.txt                    # ğŸ“¦ WHERE PYTHON DEPS RESIDE
â”œâ”€â”€ ğŸ“– README.md                           # ğŸ“š Main documentation (this file)
â””â”€â”€ ğŸ”’ .venv/                              # ğŸ Python virtual environment
```

### ğŸ¯ KEY LOCATIONS SUMMARY

| Component | Location | Purpose |
|-----------|----------|---------|
| **ğŸ§  Core Application** | `dashboard/app.py` | Main Flask web application |
| **ğŸ”§ Pipeline Logic** | `pipelines/stavanger_parking/dbt/` | dbt transformations & models |
| **ğŸ’¾ Pipeline Data** | `pipelines/stavanger_parking/data/` | Raw, staging, and processed data |
| **ğŸŒ Web Interface** | `dashboard/templates/` | HTML templates for UI |
| **âš™ï¸ Automation Scripts** | `scripts/` | Service management & automation |
| **ğŸ“š Documentation** | `docs/` | All platform documentation |
| **ğŸ—ï¸ Infrastructure** | `infrastructure/` | Deployment & service configs |
| **ğŸ› ï¸ Development Tools** | `tools/` | QA, testing, and utilities |

### ğŸ¯ Current Design Principles

**ğŸ—ï¸ Lakehouse-First Architecture:**
- Modern data lakehouse combining data lake flexibility with warehouse reliability
- ACID transactions, schema evolution, and time travel with Apache Iceberg
- Cost-effective storage with high-performance analytics

**ğŸ”§ Developer-Centric Design:**
- Clear separation between platform infrastructure and pipeline logic
- Web-based management interface for ease of use
- Docker-based deployment for consistency across environments

**ğŸ“Š Production-Ready Operations:**
- Health monitoring and automated service management
- Comprehensive logging and error handling
- Scalable architecture ready for growth

## ğŸ› ï¸ Development & Operations

### Platform Management
```bash
# Start the platform
docker-compose up -d

# Start dashboard with monitoring
./scripts/start_dashboard.sh

# Monitor dashboard health
./scripts/monitor_dashboard.sh

# Stop all services
docker-compose down
```

### Current Pipeline Operations
The **Stavanger Parking Pipeline** demonstrates:
- **Real-time Data Ingestion**: REST API data collection from municipality
- **Medallion Architecture**: Bronze (raw) â†’ Silver (clean) â†’ Gold (analytics) layers
- **Quality Assurance**: Automated dbt tests and data validation
- **Web Monitoring**: Real-time status, metrics, and data browsing

### Quality Assurance
```bash
# Run QA test suite
python tools/scripts/qa_test_suite.py

# Run service validation
python tools/scripts/service_validation_suite.py

# Manual data cleanup
python tools/scripts/cleanup_operations.py --dry-run
```

## ğŸ“š Documentation Structure

Documentation is organized in the `docs/` directory:

- **`README.md`** - Main project overview (this file)
- **`DASHBOARD_README.md`** - Dashboard usage and management guide
- **`ARCHITECTURE.md`** - Detailed system architecture
- **`PIPELINE_MANAGEMENT_GUIDE.md`** - Pipeline development workflows
- **Other docs** - Feature-specific documentation and guides

## ğŸš€ Future Roadmap

### Phase 2: Analytics Engine Integration
- **Trino Integration**: Distributed SQL queries across data sources
- **Advanced Analytics**: Complex analytical queries and reporting
- **Multi-Source Queries**: Query across different data formats

### Phase 3: Object Storage Layer
- **MinIO Integration**: S3-compatible object storage for data lake
- **Storage Optimization**: Cost-effective, scalable data storage
- **Data Lifecycle**: Automated data tiering and archival

### Phase 4: Multi-Pipeline Orchestration
- **Pipeline Templates**: Automated pipeline creation from templates
- **Orchestration Engine**: Advanced workflow management
- **Monitoring Dashboard**: Comprehensive pipeline monitoring

### Phase 5: Enterprise Features
- **Security**: Authentication, authorization, and audit trails
- **Governance**: Data lineage, quality monitoring, and compliance
- **Scalability**: Support for 50+ concurrent pipelines

## ğŸ¤ Contributing

### Getting Started
1. **Fork** the repository
2. **Clone** your fork: `git clone https://github.com/your-username/foss-dataplatform.git`
3. **Create** a feature branch: `git checkout -b feature/your-feature`
4. **Make** your changes
5. **Test** thoroughly: `docker-compose up -d && ./scripts/start_dashboard.sh`
6. **Submit** a pull request

### Development Guidelines
- **Code Quality**: Run QA tests before submitting
- **Documentation**: Update docs for any new features
- **Testing**: Ensure all existing functionality works
- **Docker**: Test changes with Docker Compose

### Areas for Contribution
- **New Pipeline Templates**: Create templates for common use cases
- **Enhanced Monitoring**: Improve dashboard features and metrics
- **Documentation**: Improve guides and examples
- **Testing**: Add more comprehensive test coverage
- **Performance**: Optimize query performance and resource usage

## ğŸ“„ License

**MIT License** - This project is open-source and free to use, modify, and distribute.

See LICENSE file for full license details.

---

## ğŸ¯ Quick Reference

| What | Where | Why |
|------|-------|-----|
| **Start Platform** | `docker-compose up -d` | Launch all services |
| **View Dashboard** | `http://localhost:5000` | Main management interface |
| **Pipeline Code** | `pipelines/stavanger_parking/dbt/` | dbt transformations |
| **Pipeline Data** | `pipelines/stavanger_parking/data/` | Raw, staging, processed data |
| **Core App** | `dashboard/app.py` | Flask web application |
| **Scripts** | `scripts/` | Automation and management |
| **Docs** | `docs/` | All documentation |

**Ready to explore? Start with:** `docker-compose up -d && ./scripts/start_dashboard.sh`
