#!/usr/bin/env python3
"""
FOSS Data Platform Dashboard

A unified web interface that provides access to all platform services,
monitoring, and management functions.
"""

from flask import Flask, render_template, jsonify, redirect, url_for, request
import requests
import json
import os
import time
from datetime import datetime
import psutil
import subprocess
from api.storage import storage_api
from api.query import trino_api
from api.platform import platform_api
from api.ingestion import ingestion_api
from api.quality import quality_api
from api.streaming import streaming_api
import random


app = Flask(__name__)

# Configuration
SERVICES = {
    'jupyterlab': {
        'name': 'JupyterLab',
        'url': 'http://jupyterlab:8888',
        'external_url': 'http://localhost:8888',
        'description': 'Interactive development environment',
        'status': 'healthy',
        'category': 'Development',
        'icon': 'ðŸ”¬'
    },
    'dagster': {
        'name': 'Dagster',
        'url': 'http://dagster:3000',
        'external_url': 'http://localhost:3000',
        'description': 'Data orchestration platform',
        'status': 'healthy',
        'category': 'Orchestration',
        'icon': 'ðŸŽ¯'
    },
    'trino': {
        'name': 'Apache Trino',
        'url': 'http://trino-coordinator:8080',
        'external_url': 'http://localhost:8080',
        'description': 'Distributed SQL query engine',
        'status': 'healthy',
        'category': 'Query Engine',
        'icon': 'ðŸš€'
    },
    'dbt': {
        'name': 'dbt',
        'url': 'http://dagster:3000',
        'external_url': 'http://localhost:3000',  # DBT runs through Dagster
        'description': 'Data transformation and modeling (via Dagster)',
        'status': 'healthy',
        'category': 'Transformation',
        'icon': 'ðŸ”§'
    },
    'minio': {
        'name': 'MinIO',
        'url': 'http://minio:9000',
        'external_url': 'http://localhost:9003',  # MinIO Console port
        'description': 'S3-compatible object storage',
        'status': 'healthy',
        'category': 'Storage',
        'icon': 'ðŸ“¦'
    },
    'grafana': {
        'name': 'Grafana',
        'url': 'http://grafana:3000',
        'external_url': 'http://localhost:3001',
        'description': 'Data visualization and monitoring',
        'status': 'healthy',
        'category': 'Visualization',
        'icon': 'ðŸ“Š'
    },
    'prometheus': {
        'name': 'Prometheus',
        'url': 'http://prometheus:9090',
        'external_url': 'http://localhost:9090',
        'description': 'Metrics collection and storage',
        'status': 'healthy',
        'category': 'Monitoring',
        'icon': 'ðŸ“ˆ'
    },
    'portainer': {
        'name': 'Portainer',
        'url': 'http://portainer:9000',
        'external_url': 'http://localhost:9000',
        'description': 'Container management interface',
        'status': 'healthy',
        'category': 'Management',
        'icon': 'ðŸ³'
    },
    'kafka': {
        'name': 'Apache Kafka',
        'url': 'http://kafka:9092',
        'external_url': 'http://localhost:9092',
        'description': 'Distributed streaming platform',
        'status': 'healthy',
        'category': 'Streaming',
        'icon': 'ðŸ“¡'
    },
    'zookeeper': {
        'name': 'Apache Zookeeper',
        'url': 'http://zookeeper:2181',
        'external_url': 'http://localhost:2181',
        'description': 'Distributed coordination service',
        'status': 'healthy',
        'category': 'Streaming',
        'icon': 'ðŸ˜'
    },
    'flink': {
        'name': 'Apache Flink',
        'url': 'http://flink-jobmanager:8081',
        'external_url': 'http://localhost:8081',
        'description': 'Stream processing engine',
        'status': 'healthy',
        'category': 'Streaming',
        'icon': 'âš¡'
    },
    'kafka-ui': {
        'name': 'Kafka UI',
        'url': 'http://kafka-ui:8080',
        'external_url': 'http://localhost:8082',
        'description': 'Kafka management interface',
        'status': 'healthy',
        'category': 'Streaming',
        'icon': 'ðŸŽ›ï¸'
    },
    'postgres': {
        'name': 'PostgreSQL',
        'url': 'http://postgres:5432',
        'external_url': 'http://localhost:5432',
        'description': 'Metadata database',
        'status': 'healthy',
        'category': 'Database',
        'icon': 'ðŸ˜'
    },
    'redis': {
        'name': 'Redis',
        'url': 'http://redis:6379',
        'external_url': 'http://localhost:6379',
        'description': 'In-memory data store',
        'status': 'healthy',
        'category': 'Cache',
        'icon': 'ðŸ”´'
    },
    'flink-taskmanager': {
        'name': 'Flink TaskManager',
        'url': 'http://flink-taskmanager:8081',
        'external_url': 'http://localhost:8081',
        'description': 'Flink task execution node',
        'status': 'healthy',
        'category': 'Streaming',
        'icon': 'âš¡'
    },
    'trino-worker': {
        'name': 'Trino Worker',
        'url': 'http://trino-worker:8080',
        'external_url': 'http://localhost:8080',
        'description': 'Trino worker node',
        'status': 'healthy',
        'category': 'Query Engine',
        'icon': 'ðŸš€'
    }
}

def check_service_health(service_id, service_info):
    """Check if a service is healthy"""
    try:
        # Special handling for Portainer to check API endpoint
        if service_id == 'portainer':
            response = requests.get('http://localhost:9000/api/status', timeout=3)
        else:
            response = requests.get(service_info['url'], timeout=3)
            
        if response.status_code == 200:
            return 'healthy'
        else:
            return 'warning'
    except requests.exceptions.RequestException:
        return 'down'

def get_system_metrics():
    """Get basic system metrics"""
    try:
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        return {
            'cpu': round(cpu_percent, 1),
            'memory': {
                'used': round(memory.used / (1024**3), 1),  # GB
                'total': round(memory.total / (1024**3), 1),  # GB
                'percent': round(memory.percent, 1)
            },
            'disk': {
                'used': round(disk.used / (1024**3), 1),  # GB
                'total': round(disk.total / (1024**3), 1),  # GB
                'percent': round((disk.used / disk.total) * 100, 1)
            }
        }
    except Exception:
        return None

def get_docker_status():
    """Get Docker container status"""
    try:
        # Try to use Docker socket if available and docker command exists
        if os.path.exists('/var/run/docker.sock'):
            try:
                result = subprocess.run(['docker', 'ps', '--format', '{{.Names}}:{{.Status}}'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    containers = {}
                    for line in result.stdout.strip().split('\n'):
                        if ':' in line:
                            name, status = line.split(':', 1)
                            containers[name] = status
                    return containers
            except FileNotFoundError:
                # Docker command not available in container
                pass
        
        # Fallback: return service-based status
        return {
            'dashboard': 'Up (Service-based monitoring)',
            'dagster': 'Up (Service-based monitoring)',
            'jupyterlab': 'Up (Service-based monitoring)',
            'trino-coordinator': 'Up (Service-based monitoring)',
            'grafana': 'Up (Service-based monitoring)',
            'minio': 'Up (Service-based monitoring)',
            'prometheus': 'Up (Service-based monitoring)',
            'portainer': 'Up (Service-based monitoring)',
            'postgres': 'Up (Service-based monitoring)',
            'redis': 'Up (Service-based monitoring)'
        }
    except Exception:
        return {}

# Add pipeline status function
def get_pipeline_status():
    """Get Stavanger Parking pipeline status from actual Trino data"""
    try:
        import requests
        import json
        
        # Query actual pipeline models from Trino
        queries = {
            'models_count': "SELECT COUNT(*) as count FROM information_schema.tables WHERE table_schema LIKE '%marts%' OR table_schema LIKE '%staging%' OR table_schema LIKE '%intermediate%'",
            'total_records': "SELECT COUNT(*) as count FROM memory.default_staging.stg_parking_data",
            'locations_count': "SELECT COUNT(DISTINCT parking_location) as count FROM memory.default_staging.stg_parking_data",
            'critical_alerts': "SELECT COUNT(*) as count FROM memory.default_marts_marketing.mart_parking_insights WHERE business_recommendation LIKE '%Consider Expansion%'",
            'avg_utilization': "SELECT ROUND(AVG(daily_avg_utilization), 1) as avg_util FROM memory.default_marts_marketing.mart_parking_insights"
        }
        
        results = {}
        for key, query in queries.items():
            try:
                # Use Trino's HTTP API to execute queries
                response = requests.post(
                    'http://localhost:8080/v1/statement',
                    json={'query': query},
                    headers={'Content-Type': 'application/json'},
                    timeout=10
                )
                if response.status_code == 200:
                    # Parse the response to get the count
                    result_data = response.json()
                    if 'data' in result_data and result_data['data']:
                        results[key] = result_data['data'][0][0]  # Extract the count value
                    else:
                        results[key] = 0
                else:
                    results[key] = 0
            except:
                results[key] = 0
        
        # Get business insights from actual data
        try:
            insights_query = """
            SELECT DISTINCT parking_location, business_recommendation 
            FROM memory.default_marts_marketing.mart_parking_insights 
            WHERE business_recommendation LIKE '%Consider Expansion%' 
            LIMIT 5
            """
            insights_response = requests.post(
                'http://localhost:8080/v1/statement',
                json={'query': insights_query},
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            business_insights = []
            if insights_response.status_code == 200:
                insights_data = insights_response.json()
                if 'data' in insights_data:
                    for row in insights_data['data']:
                        business_insights.append(f"{row[0]}: {row[1]}")
        except:
            business_insights = [
                'Stavanger Sentrum: High Demand - Consider Expansion',
                'Tasta: High Demand - Consider Expansion',
                'HillevÃ¥g: High Demand - Consider Expansion'
            ]
        
        return {
            'status': 'running',
            'last_run': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # 24-hour format
            'models_count': results.get('models_count', 5),
            'tests_passed': 3,  # We'll enhance this later
            'data_quality': 'good',
            'business_insights': business_insights,
            'total_locations': results.get('locations_count', 8),
            'avg_utilization': f"{results.get('avg_utilization', 75)}%",
            'critical_alerts': results.get('critical_alerts', 1),
            'total_records': results.get('total_records', 1000)
        }
    except Exception as e:
        print(f"Error getting pipeline status: {e}")
        return {
            'status': 'unknown',
            'last_run': 'N/A',
            'models_count': 0,
            'tests_passed': 0,
            'data_quality': 'unknown',
            'business_insights': [],
            'total_locations': 0,
            'avg_utilization': 'N/A',
            'critical_alerts': 0,
            'total_records': 0
        }

# Add pipeline metrics function
def get_pipeline_metrics():
    """Get key pipeline metrics from actual Trino data"""
    try:
        import requests
        import json
        
        # Query actual metrics from Trino
        metrics_query = """
        SELECT 
            COUNT(*) as total_records,
            COUNT(DISTINCT parking_location) as locations_monitored,
            ROUND(AVG(utilization_rate), 1) as avg_utilization,
            MAX(utilization_rate) as max_utilization,
            COUNT(CASE WHEN is_peak_hour = 1 THEN 1 END) as peak_hour_count,
            COUNT(CASE WHEN occupancy_status = 'Critical' THEN 1 END) as critical_count
        FROM memory.default_staging.stg_parking_data
        """
        
        try:
            response = requests.post(
                'http://localhost:8080/v1/statement',
                json={'query': metrics_query},
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            if response.status_code == 200:
                result_data = response.json()
                if 'data' in result_data and result_data['data']:
                    row = result_data['data'][0]
                    return {
                        'total_records': row[0],
                        'locations_monitored': row[1],
                        'utilization_threshold': f"{row[2]}%",
                        'peak_hours': '08:00-09:00, 17:00-18:00',
                        'data_freshness': '1 hour',
                        'pipeline_health': 'excellent',
                        'max_utilization': f"{row[3]}%",
                        'peak_hour_percentage': f"{(row[4]/row[0]*100):.1f}%" if row[0] > 0 else "0%",
                        'critical_percentage': f"{(row[5]/row[0]*100):.1f}%" if row[0] > 0 else "0%"
                    }
        except:
            pass
        
        # Fallback to sample data
        return {
            'total_records': 0,
            'locations_monitored': 0,
            'utilization_threshold': 'N/A',
            'peak_hours': 'N/A',
            'data_freshness': 'N/A',
            'pipeline_health': 'unknown',
            'max_utilization': 'N/A',
            'peak_hour_percentage': 'N/A',
            'critical_percentage': 'N/A'
        }
    except Exception as e:
        print(f"Error getting pipeline metrics: {e}")
        return {
            'total_records': 0,
            'locations_monitored': 0,
            'utilization_threshold': 'N/A',
            'peak_hours': 'N/A',
            'data_freshness': 'N/A',
            'pipeline_health': 'unknown',
            'max_utilization': 'N/A',
            'peak_hour_percentage': 'N/A',
            'critical_percentage': 'N/A'
        }

@app.route('/')
def dashboard():
    """Main dashboard page"""
    # Check service health
    service_status = {}
    for service_id, service_info in SERVICES.items():
        service_status[service_id] = {
            **service_info,
            'status': check_service_health(service_id, service_info)
        }
    
    # Get system metrics
    system_metrics = get_system_metrics()
    
    # Get Docker status
    docker_status = get_docker_status()
    
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # 24-hour format
    return render_template('dashboard.html',
                         services=service_status,
                         system_metrics=system_metrics,
                         docker_status=docker_status,
                         timestamp=timestamp)

@app.route('/api/health')
def api_health():
    """API endpoint for service health checks"""
    health_status = {}
    for service_id, service_info in SERVICES.items():
        health_status[service_id] = {
            'name': service_info['name'],
            'status': check_service_health(service_id, service_info),
            'url': service_info['url']
        }
    
    return jsonify({
        'timestamp': datetime.now().isoformat(),
        'services': health_status
    })

@app.route('/health')
def health_page():
    """Human-readable health check page"""
    health_status = {}
    for service_id, service_info in SERVICES.items():
        health_status[service_id] = {
            'name': service_info['name'],
            'status': check_service_health(service_id, service_info),
            'url': service_info['url'],
            'description': service_info.get('description'),
            'icon': service_info.get('icon'),
            'category': service_info.get('category'),
            'external_url': service_info.get('external_url')
        }
    
    # Include system and docker metrics for consolidated view
    system_metrics = get_system_metrics()
    docker_status = get_docker_status()
    
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')  # 24-hour format
    return render_template('health.html', services=health_status, system_metrics=system_metrics, docker_status=docker_status, timestamp=timestamp)

@app.route('/api/metrics')
def api_metrics():
    """API endpoint for system metrics"""
    return jsonify({
        'timestamp': datetime.now().isoformat(),
        'system': get_system_metrics(),
        'docker': get_docker_status()
    })

@app.route('/metrics')
def metrics_page():
    """Redirect consolidated metrics view to health page"""
    return redirect(url_for('health_page'))

@app.route('/service/<service_id>')
def service_redirect(service_id):
    """Redirect to a specific service"""
    if service_id in SERVICES:
        return redirect(SERVICES[service_id]['external_url'])
    else:
        return "Service not found", 404



@app.route('/pipeline')
def pipeline_status():
    """Pipeline status page"""
    pipeline_status = get_pipeline_status_data()
    pipeline_metrics = get_pipeline_metrics()
    
    return render_template('pipeline.html', 
                         pipeline_status=pipeline_status,
                         pipeline_metrics=pipeline_metrics)

@app.route('/api/pipeline/status')
def api_pipeline_status():
    """API endpoint for pipeline status"""
    return jsonify(get_pipeline_status())

@app.route('/api/pipeline/metrics')
def api_pipeline_metrics():
    """API endpoint for pipeline metrics"""
    return jsonify(get_pipeline_metrics())

@app.route('/api/pipeline/run', methods=['POST'])
def run_pipeline():
    """Run a specific pipeline"""
    try:
        import subprocess
        import os
        import json
        
        data = request.get_json()
        pipeline_name = data.get('pipeline')
        
        if not pipeline_name:
            return jsonify({
                'success': False,
                'error': 'Pipeline name is required'
            }), 400
        
        # Map pipeline names to project directories
        pipeline_configs = {
            'stavanger_parking': {
                'project_dir': 'dbt_stavanger_parking',
                'commands': [
                    ['dbt', 'seed', '--target', 'dev'],
                    ['dbt', 'run', '--target', 'dev'],
                    ['dbt', 'test', '--target', 'dev']
                ]
            }
        }
        
        if pipeline_name not in pipeline_configs:
            return jsonify({
                'success': False,
                'error': f'Unknown pipeline: {pipeline_name}'
            }), 400
        
        config = pipeline_configs[pipeline_name]
        project_dir = config['project_dir']
        
        if not os.path.exists(project_dir):
            return jsonify({
                'success': False,
                'error': f'Project directory not found: {project_dir}'
            }), 400
        
        # Run dbt commands using host environment
        results = []
        for cmd in config['commands']:
            try:
                # Use dbt from container installation
                cmd[0] = 'dbt'
                
                result = subprocess.run(
                    cmd, 
                    cwd=project_dir, 
                    capture_output=True, 
                    text=True, 
                    timeout=300,
                    env=os.environ.copy()
                )
                results.append({
                    'command': ' '.join(cmd),
                    'success': result.returncode == 0,
                    'output': result.stdout if result.stdout else '',
                    'error': result.stderr if result.stderr else ''
                })
            except subprocess.TimeoutExpired:
                results.append({
                    'command': ' '.join(cmd),
                    'success': False,
                    'output': '',
                    'error': 'Command timed out after 5 minutes'
                })
            except Exception as e:
                results.append({
                    'command': ' '.join(cmd),
                    'success': False,
                    'output': '',
                    'error': f'Command failed: {str(e)}'
                })
        
        # Check if core pipeline (seed + run) succeeded
        core_pipeline_success = results[0]['success'] and results[1]['success']  # seed and run
        tests_success = results[2]['success'] if len(results) > 2 else True
        
        pipeline_status = 'success' if core_pipeline_success else 'failed'
        message = 'Pipeline executed successfully' if core_pipeline_success else 'Pipeline execution failed'
        
        if core_pipeline_success and not tests_success:
            message = 'Pipeline executed successfully (tests failed - check data quality)'
        
        return jsonify({
            'success': core_pipeline_success,
            'results': results,
            'message': message,
            'pipeline_status': pipeline_status,
            'tests_passed': tests_success,
            'pipeline_name': pipeline_name
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Failed to execute pipeline: {str(e)}'
        }), 500

@app.route('/api/pipeline/run-model', methods=['POST'])
def run_specific_model():
    """Run a specific dbt model"""
    try:
        import subprocess
        import os
        import json
        
        data = request.get_json()
        model_name = data.get('model_name')
        
        if not model_name:
            return jsonify({'success': False, 'error': 'Model name is required'}), 400
        
        # Change to dbt project directory - use symlink in dashboard directory
        project_dir = 'dbt_stavanger_parking'
        
        if not os.path.exists(project_dir):
            return jsonify({
                'success': False,
                'output': '',
                'error': f'Project directory not found: {project_dir}',
                'results': [{
                    'command': f'dbt run --select {model_name}',
                    'success': False,
                    'output': '',
                    'error': f'Project directory not found: {project_dir}'
                }]
            }), 400
        
        result = subprocess.run(
            ['dbt', 'run', '--select', model_name, '--target', 'dev'],
            cwd=project_dir,
            capture_output=True,
            text=True,
            timeout=300
        )
        
        return jsonify({
            'success': result.returncode == 0,
            'output': result.stdout if result.stdout else '',
            'error': result.stderr if result.stderr else '',
            'results': [{
                'command': f'dbt run --select {model_name}',
                'success': result.returncode == 0,
                'output': result.stdout if result.stdout else '',
                'error': result.stderr if result.stderr else ''
            }]
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'output': '',
            'error': f'Failed to run model: {str(e)}',
            'results': [{
                'command': f'dbt run --select {model_name}',
                'success': False,
                'output': '',
                'error': f'Failed to run model: {str(e)}'
            }]
        }), 500

@app.route('/api/pipeline/test', methods=['POST'])
def run_tests():
    """Run dbt tests"""
    try:
        import subprocess
        import os
        
        # Change to dbt project directory - use symlink in dashboard directory
        project_dir = 'dbt_stavanger_parking'
        
        if not os.path.exists(project_dir):
            return jsonify({
                'success': False,
                'output': '',
                'error': f'Project directory not found: {project_dir}',
                'tests_passed': False,
                'results': [{
                    'command': 'dbt test --target dev',
                    'success': False,
                    'output': '',
                    'error': f'Project directory not found: {project_dir}'
                }]
            }), 400
        
        result = subprocess.run(
            ['dbt', 'test', '--target', 'dev'],
            cwd=project_dir,
            capture_output=True,
            text=True,
            timeout=300
        )
        
        return jsonify({
            'success': result.returncode == 0,
            'output': result.stdout if result.stdout else '',
            'error': result.stderr if result.stderr else '',
            'tests_passed': result.returncode == 0,
            'results': [{
                'command': 'dbt test --target dev',
                'success': result.returncode == 0,
                'output': result.stdout if result.stdout else '',
                'error': result.stderr if result.stderr else ''
            }]
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'output': '',
            'error': f'Failed to run tests: {str(e)}',
            'tests_passed': False,
            'results': [{
                'command': 'dbt test --target dev',
                'success': False,
                'output': '',
                'error': f'Failed to run tests: {str(e)}'
            }]
        }), 500

@app.route('/api/pipeline/status-detail')
def get_pipeline_status_detail():
    """Get detailed pipeline status including model states"""
    try:
        import subprocess
        import os
        import json
        
        project_dir = 'dbt_stavanger_parking'
        
        # Get dbt project status
        result = subprocess.run(
            ['dbt', 'list', '--target', 'dev'],
            cwd=project_dir,
            capture_output=True,
            text=True,
            timeout=60
        )
        
        models = []
        if result.returncode == 0:
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    models.append({
                        'name': line.strip(),
                        'status': 'available'
                    })
        
        return jsonify({
            'models': models,
            'total_models': len(models),
            'project_status': 'healthy' if result.returncode == 0 else 'error'
        })
        
    except Exception as e:
        return jsonify({
            'error': str(e),
            'models': [],
            'total_models': 0,
            'project_status': 'unknown'
        }), 500

@app.route('/data-browser')
def data_browser():
    """Data browser page for interactive data exploration"""
    return render_template('data_browser.html')

@app.route('/streaming')
def streaming():
    """Real-time streaming dashboard"""
    return render_template('streaming.html')

@app.route('/api/query/execute', methods=['POST'])
def execute_query():
    """Execute SQL query via Trino"""
    try:
        import requests
        import json
        import time
        
        data = request.get_json()
        query = data.get('query')
        
        if not query:
            return jsonify({'success': False, 'error': 'No query provided'}), 400
        
        # Trino query execution
        start_time = time.time()
        
        # Execute query via Trino HTTP API
        trino_url = "http://trino-coordinator:8080/v1/statement"
        headers = {
            'Content-Type': 'application/json',
            'X-Trino-User': 'trino'
        }
        
        response = requests.post(trino_url, data=query, headers=headers, timeout=30)
        
        if response.status_code != 200:
            return jsonify({
                'success': False, 
                'error': f'Trino API error: {response.status_code}'
            }), 500
        
        # Get query results
        query_id = response.json().get('id')
        if not query_id:
            return jsonify({
                'success': False, 
                'error': 'No query ID returned from Trino'
            }), 500
        
        # Poll for results with longer timeout for complex queries
        max_attempts = 200  # Increased significantly for complex queries
        poll_interval = 0.5  # Increased slightly for better performance
        
        print(f"Starting to poll for query {query_id}")
        
        # Get the nextUri from the initial response
        next_uri = response.json().get('nextUri')
        if not next_uri:
            return jsonify({
                'success': False,
                'error': 'No nextUri in Trino response'
            }), 500
        
        print(f"Using nextUri: {next_uri}")
        
        for attempt in range(max_attempts):
            time.sleep(poll_interval)
            print(f"Poll attempt {attempt + 1}/{max_attempts}")
            
            try:
                # Use the nextUri directly
                result_response = requests.get(next_uri, headers=headers, timeout=10)
                print(f"Response status: {result_response.status_code}")
                print(f"Response headers: {dict(result_response.headers)}")
                
                if result_response.status_code == 200:
                    result_data = result_response.json()
                    print(f"Full response data: {json.dumps(result_data, indent=2)}")
                    current_state = result_data.get('stats', {}).get('state')
                    print(f"Query state: {current_state}")
                    print(f"Response keys: {list(result_data.keys())}")
                    
                    # Update nextUri for next iteration (Trino provides new URI each time)
                    new_next_uri = result_data.get('nextUri')
                    if new_next_uri:
                        next_uri = new_next_uri
                        print(f"Updated nextUri: {next_uri}")
                    
                    if current_state == 'FINISHED':
                        # Extract results
                        columns = [col['name'] for col in result_data.get('columns', [])]
                        data_rows = result_data.get('data', [])
                        
                        # Convert to list of dicts
                        results = []
                        for row in data_rows:
                            row_dict = {}
                            for i, col in enumerate(columns):
                                row_dict[col] = row[i] if i < len(row) else None
                            results.append(row_dict)
                        
                        execution_time = int((time.time() - start_time) * 1000)
                        print(f"Query completed successfully in {execution_time}ms")
                        
                        return jsonify({
                            'success': True,
                            'results': results,
                            'columns': columns,
                            'execution_time': execution_time,
                            'row_count': len(results)
                        })
                    
                    elif current_state == 'FAILED':
                        error_msg = result_data.get('error', {}).get('message', 'Unknown error')
                        print(f"Query failed: {error_msg}")
                        return jsonify({
                            'success': False,
                            'error': f'Query failed: {error_msg}'
                        }), 500
                    
                    elif current_state in ['RUNNING', 'QUEUED']:
                        # Continue polling
                        print(f"Query {current_state.lower()}, continuing to poll...")
                        continue
                    
                    # If we get here, the state is something unexpected
                    print(f"Unexpected query state: {current_state}")
                    continue
                    
                elif result_response.status_code == 410:
                    # Query is gone, might be completed
                    print("Query returned 410 Gone, checking if it completed")
                    # Try to get the final status from the query ID
                    final_response = requests.get(f"http://trino-coordinator:8080/v1/query/{query_id}", headers=headers, timeout=10)
                    if final_response.status_code == 200:
                        final_data = final_response.json()
                        if final_data.get('state') == 'FINISHED':
                            # Extract results from final response
                            columns = [col['name'] for col in final_data.get('columns', [])]
                            data_rows = final_data.get('data', [])
                            
                            results = []
                            for row in data_rows:
                                row_dict = {}
                                for i, col in enumerate(columns):
                                    row_dict[col] = row[i] if i < len(row) else None
                                results.append(row_dict)
                            
                            execution_time = int((time.time() - start_time) * 1000)
                            print(f"Query completed successfully in {execution_time}ms")
                            
                            return jsonify({
                                'success': True,
                                'results': results,
                                'columns': columns,
                                'execution_time': execution_time,
                                'row_count': len(results)
                            })
                        else:
                            print(f"Query state in final response: {final_data.get('state')}")
                            # If query is not finished, it might have failed
                            if final_data.get('state') == 'FAILED':
                                error_msg = final_data.get('error', {}).get('message', 'Unknown error')
                                return jsonify({
                                    'success': False,
                                    'error': f'Query failed: {error_msg}'
                                }), 500
                    
                    # If we can't get results from the final response, the query might be too fast
                    # Try to get results directly from the nextUri with a different approach
                    print("Query completed too fast, trying direct result retrieval")
                    try:
                        # For fast queries, try to get results immediately
                        direct_response = requests.get(next_uri, headers=headers, timeout=5)
                        if direct_response.status_code == 200:
                            direct_data = direct_response.json()
                            if direct_data.get('state') == 'FINISHED':
                                columns = [col['name'] for col in direct_data.get('columns', [])]
                                data_rows = direct_data.get('data', [])
                                
                                results = []
                                for row in data_rows:
                                    row_dict = {}
                                    for i, col in enumerate(columns):
                                        row_dict[col] = row[i] if i < len(row) else None
                                    results.append(row_dict)
                                
                                execution_time = int((time.time() - start_time) * 1000)
                                print(f"Query completed successfully in {execution_time}ms")
                                
                                return jsonify({
                                    'success': True,
                                    'results': results,
                                    'columns': columns,
                                    'execution_time': execution_time,
                                    'row_count': len(results)
                                })
                    except Exception as e:
                        print(f"Direct result retrieval failed: {e}")
                    
                    continue
                    
                else:
                    print(f"Unexpected response status: {result_response.status_code}")
                    print(f"Response text: {result_response.text[:200]}")
                    
            except requests.exceptions.Timeout:
                print(f"Timeout on poll attempt {attempt + 1}")
                continue
            except Exception as e:
                print(f"Error on poll attempt {attempt + 1}: {e}")
                continue
        
        # If we get here, the query timed out
        total_timeout = max_attempts * poll_interval
        return jsonify({
            'success': False,
            'error': f'Query execution timed out after {total_timeout:.1f} seconds. This may indicate:\n\n1. The table/catalog does not exist\n2. The query is too complex\n3. Trino service is overloaded\n\nTry:\n- Using the memory catalog instead of iceberg\n- Checking table names in the schema browser\n- Running a simpler query first\n\nNote: Complex queries may take up to {total_timeout:.0f} seconds to complete.'
        }), 500
        
    except requests.exceptions.Timeout:
        return jsonify({
            'success': False,
            'error': 'Request to Trino timed out. Please check if Trino is running and accessible.'
        }), 500
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Failed to execute query: {str(e)}'
        }), 500

@app.route('/api/query/test-connection')
def test_trino_connection():
    """Simple test endpoint to debug Trino connection"""
    try:
        import requests
        
        # Test 1: Simple GET request to Trino UI
        ui_response = requests.get('http://trino-coordinator:8080/ui/', timeout=5)
        
        # Test 2: POST request to statement endpoint
        statement_response = requests.post(
            'http://trino-coordinator:8080/v1/statement',
            data='SHOW CATALOGS',
            headers={'Content-Type': 'application/json', 'X-Trino-User': 'trino'},
            timeout=10
        )
        
        return jsonify({
            'success': True,
            'ui_status': ui_response.status_code,
            'statement_status': statement_response.status_code,
            'statement_response': statement_response.text[:500] if statement_response.status_code == 200 else 'N/A'
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }), 500

@app.route('/api/query/simple-test')
def simple_trino_test():
    """Very simple test to see what Trino returns"""
    try:
        import requests
        
        # Make a simple request to Trino
        response = requests.post(
            'http://trino-coordinator:8080/v1/statement',
            data='SHOW CATALOGS',
            headers={'Content-Type': 'application/json', 'X-Trino-User': 'trino'},
            timeout=10
        )
        
        if response.status_code == 200:
            # Get the query ID and immediately check its status
            query_data = response.json()
            query_id = query_data.get('id')
            
            if query_id:
                # Wait a moment and check the status
                import time
                time.sleep(1)
                
                status_response = requests.get(
                    f'http://trino-coordinator:8080/v1/query/{query_id}',
                    headers={'X-Trino-User': 'trino'},
                    timeout=10
                )
                
                return jsonify({
                    'success': True,
                    'initial_response': query_data,
                    'status_response': status_response.json() if status_response.status_code == 200 else {'error': status_response.text},
                    'status_code': status_response.status_code
                })
            else:
                return jsonify({
                    'success': False,
                    'error': 'No query ID in response',
                    'response': query_data
                })
        else:
            return jsonify({
                'success': False,
                'error': f'Trino returned status {response.status_code}',
                'response_text': response.text
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }), 500

@app.route('/api/query/debug-test')
def debug_trino_communication():
    """Comprehensive test endpoint to debug Trino communication"""
    try:
        import requests
        import json
        
        debug_info = {
            'dashboard_container': 'dashboard',
            'trino_container': 'trino-coordinator',
            'test_results': []
        }
        
        # Test 1: Basic connectivity
        try:
            ui_response = requests.get('http://trino-coordinator:8080/ui/', timeout=5)
            debug_info['test_results'].append({
                'test': 'Basic connectivity to Trino UI',
                'status': 'SUCCESS' if ui_response.status_code == 200 else 'FAILED',
                'status_code': ui_response.status_code,
                'response_size': len(ui_response.text)
            })
        except Exception as e:
            debug_info['test_results'].append({
                'test': 'Basic connectivity to Trino UI',
                'status': 'ERROR',
                'error': str(e)
            })
        
        # Test 2: Submit simple query
        try:
            query_response = requests.post(
                'http://trino-coordinator:8080/v1/statement',
                data='SELECT 1 as test',
                headers={'Content-Type': 'application/json', 'X-Trino-User': 'trino'},
                timeout=10
            )
            
            if query_response.status_code == 200:
                query_data = query_response.json()
                query_id = query_data.get('id')
                next_uri = query_data.get('nextUri')
                
                debug_info['test_results'].append({
                    'test': 'Submit simple query',
                    'status': 'SUCCESS',
                    'query_id': query_id,
                    'next_uri': next_uri,
                    'initial_state': query_data.get('stats', {}).get('state')
                })
                
                # Test 3: Follow nextUri chain
                if next_uri:
                    chain_results = []
                    current_uri = next_uri
                    max_chain_length = 5
                    
                    for i in range(max_chain_length):
                        try:
                            chain_response = requests.get(current_uri, headers={'X-Trino-User': 'trino'}, timeout=5)
                            if chain_response.status_code == 200:
                                chain_data = chain_response.json()
                                current_state = chain_data.get('stats', {}).get('state')
                                new_next_uri = chain_data.get('nextUri')
                                
                                chain_results.append({
                                    'step': i + 1,
                                    'uri': current_uri,
                                    'state': current_state,
                                    'new_next_uri': new_next_uri
                                })
                                
                                if current_state == 'FINISHED':
                                    debug_info['test_results'].append({
                                        'test': 'Follow nextUri chain',
                                        'status': 'SUCCESS - Query completed',
                                        'steps': chain_results,
                                        'final_state': current_state
                                    })
                                    break
                                elif current_state == 'FAILED':
                                    debug_info['test_results'].append({
                                        'test': 'Follow nextUri chain',
                                        'status': 'FAILED - Query failed',
                                        'steps': chain_results,
                                        'final_state': current_state
                                    })
                                    break
                                elif new_next_uri:
                                    current_uri = new_next_uri
                                else:
                                    debug_info['test_results'].append({
                                        'test': 'Follow nextUri chain',
                                        'status': 'STUCK - No nextUri provided',
                                        'steps': chain_results,
                                        'final_state': current_state
                                    })
                                    break
                            else:
                                chain_results.append({
                                    'step': i + 1,
                                    'uri': current_uri,
                                    'status_code': chain_response.status_code,
                                    'error': chain_response.text[:200]
                                })
                                debug_info['test_results'].append({
                                    'test': 'Follow nextUri chain',
                                    'status': f'ERROR - HTTP {chain_response.status_code}',
                                    'steps': chain_results
                                })
                                break
                        except Exception as e:
                            chain_results.append({
                                'step': i + 1,
                                'uri': current_uri,
                                'error': str(e)
                            })
                            debug_info['test_results'].append({
                                'test': 'Follow nextUri chain',
                                'status': f'ERROR - Exception: {str(e)}',
                                'steps': chain_results
                            })
                            break
                    else:
                        debug_info['test_results'].append({
                            'test': 'Follow nextUri chain',
                            'status': 'TIMEOUT - Max chain length reached',
                            'steps': chain_results
                        })
            else:
                debug_info['test_results'].append({
                    'test': 'Submit simple query',
                    'status': 'FAILED',
                    'status_code': query_response.status_code,
                    'error': query_response.text[:200]
                })
                
        except Exception as e:
            debug_info['test_results'].append({
                'test': 'Submit simple query',
                'status': 'ERROR',
                'error': str(e)
            })
        
        return jsonify(debug_info)
        
    except Exception as e:
        return jsonify({
            'error': f'Debug test failed: {str(e)}'
        }), 500

@app.route('/pipeline-management')
def pipeline_management():
    """Pipeline Management page - manage multiple pipelines"""
    # Mock data for now - will be replaced with real pipeline registry
    pipeline_stats = {
        'total_pipelines': 1,
        'running_pipelines': 1,
        'warning_pipelines': 0,
        'error_pipelines': 0
    }
    
    pipelines = [
        {
            'id': 'stavanger_parking',
            'name': 'Stavanger Parking',
            'type': 'dbt',
            'description': 'Real-time parking utilization insights and business intelligence',
            'status': 'Running',
            'last_run': '2025-09-01 15:33:59',
            'models_count': 5,
            'success_rate': 85
        }
    ]
    
    recent_executions = [
        {
            'pipeline_name': 'Stavanger Parking',
            'timestamp': '2025-09-01 15:33:59',
            'status': 'SUCCESS',
            'status_color': 'success'
        }
    ]
    
    recent_alerts = [
        {
            'pipeline_name': 'Stavanger Parking',
            'message': 'Some tests failed - check data quality',
            'severity': 'warning'
        }
    ]
    
    return render_template('pipeline_management.html', 
                         pipeline_stats=pipeline_stats,
                         pipelines=pipelines,
                         recent_executions=recent_executions,
                         recent_alerts=recent_alerts)

@app.route('/pipeline-control')
def pipeline_control():
    """Pipeline Control page - execute and monitor pipelines"""
    # Get pipeline parameter from query string
    pipeline_id = request.args.get('pipeline', 'stavanger_parking')
    
    # For now, only support the existing stavanger_parking pipeline
    if pipeline_id == 'stavanger_parking':
        pipelines = [
            {
                'id': 'stavanger_parking',
                'name': 'Stavanger Parking',
                'type': 'dbt'
            }
        ]
        selected_pipeline = 'stavanger_parking'
    else:
        pipelines = []
        selected_pipeline = None
    
    return render_template('pipeline_control.html', 
                         pipelines=pipelines, 
                         selected_pipeline=selected_pipeline)

@app.route('/api/pipeline', methods=['POST'])
def create_pipeline():
    """Create a new pipeline"""
    try:
        data = request.get_json()
        
        # Mock implementation - in real system this would save to database
        pipeline_id = f"pipeline_{int(time.time())}"
        
        return jsonify({
            'success': True,
            'pipeline_id': pipeline_id,
            'message': 'Pipeline created successfully'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pipeline/<pipeline_id>', methods=['DELETE'])
def delete_pipeline(pipeline_id):
    """Delete a pipeline"""
    try:
        # Mock implementation - in real system this would delete from database
        return jsonify({
            'success': True,
            'message': f'Pipeline {pipeline_id} deleted successfully'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pipeline/<pipeline_id>/run', methods=['POST'])
def run_specific_pipeline(pipeline_id):
    """Run a specific pipeline"""
    try:
        data = request.get_json()
        target = data.get('target', 'dev')
        
        if pipeline_id == 'stavanger_parking':
            # Create execution tracking file
            execution_file = f'/tmp/pipeline_{pipeline_id}_execution.json'
            execution_data = {
                'pipeline_id': pipeline_id,
                'status': 'RUNNING',
                'start_time': time.time(),
                'target': target,
                'pid': None
            }
            
            # Start pipeline execution in background
            try:
                # Run the pipeline
                result = run_pipeline()
                
                if result.json['success']:
                    # Update execution data with success
                    execution_data['status'] = 'FINISHED'
                    execution_data['end_time'] = time.time()
                    execution_data['result'] = result.json
                    
                    # Update timestamp in pipeline status
                    update_pipeline_timestamp(pipeline_id)
                    
                    with open(execution_file, 'w') as f:
                        json.dump(execution_data, f)
                    
                    return jsonify({
                        'success': True,
                        'message': 'Pipeline execution completed successfully',
                        'execution_id': f'exec_{int(time.time())}'
                    })
                else:
                    # Update execution data with failure
                    execution_data['status'] = 'FAILED'
                    execution_data['end_time'] = time.time()
                    execution_data['error'] = result.json.get('error', 'Unknown error')
                    
                    with open(execution_file, 'w') as f:
                        json.dump(execution_data, f)
                    
                    return jsonify({
                        'success': False,
                        'error': result.json.get('error', 'Pipeline execution failed')
                    })
                    
            except Exception as e:
                # Update execution data with error
                execution_data['status'] = 'FAILED'
                execution_data['end_time'] = time.time()
                execution_data['error'] = str(e)
                
                with open(execution_file, 'w') as f:
                    json.dump(execution_data, f)
                
                return jsonify({
                    'success': False,
                    'error': f'Pipeline execution error: {str(e)}'
                }), 500
        else:
            return jsonify({
                'success': False,
                'error': f'Pipeline {pipeline_id} not found'
            }), 404
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pipeline/<pipeline_id>/status')
def get_pipeline_status(pipeline_id):
    """Get status of a specific pipeline"""
    try:
        # For now, only support the existing stavanger_parking pipeline
        if pipeline_id == 'stavanger_parking':
            return jsonify(get_pipeline_status_data())
        else:
            return jsonify({
                'success': False,
                'error': f'Pipeline {pipeline_id} not found'
            }), 404
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pipeline/<pipeline_id>/execution-status', methods=['GET'])
def get_pipeline_execution_status(pipeline_id):
    """Get real-time execution status for a specific pipeline"""
    try:
        if pipeline_id == 'stavanger_parking':
            # Check if there's an active execution
            execution_file = f'/tmp/pipeline_{pipeline_id}_execution.json'
            
            if os.path.exists(execution_file):
                with open(execution_file, 'r') as f:
                    execution_data = json.load(f)
                
                # Check if execution is still running
                if execution_data.get('status') == 'RUNNING':
                    # Check if the process is still alive
                    try:
                        os.kill(execution_data['pid'], 0)  # Check if process exists
                        return jsonify({
                            'status': 'RUNNING',
                            'message': 'Pipeline execution in progress',
                            'start_time': execution_data['start_time'],
                            'elapsed_time': time.time() - execution_data['start_time']
                        })
                    except OSError:
                        # Process died, mark as failed
                        execution_data['status'] = 'FAILED'
                        execution_data['end_time'] = time.time()
                        execution_data['error'] = 'Process terminated unexpectedly'
                        with open(execution_file, 'w') as f:
                            json.dump(execution_data, f)
                        return jsonify({
                            'status': 'FAILED',
                            'error': 'Process terminated unexpectedly',
                            'start_time': execution_data['start_time'],
                            'end_time': execution_data['end_time']
                        })
                else:
                    # Execution completed, return final status
                    return jsonify(execution_data)
            else:
                # No active execution
                return jsonify({
                    'status': 'IDLE',
                    'message': 'No active execution'
                })
        else:
            return jsonify({
                'success': False,
                'error': f'Pipeline {pipeline_id} not found'
            }), 404
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pipeline/<pipeline_id>')
def get_pipeline(pipeline_id):
    """Get pipeline data"""
    try:
        # For now, only support the existing stavanger_parking pipeline
        if pipeline_id == 'stavanger_parking':
            pipeline_data = {
                'name': 'Stavanger Parking',
                'type': 'dbt',
                'description': 'Real-time parking utilization insights and business intelligence',
                'project_dir': 'dbt_stavanger_parking',
                'target': 'dev',
                'schedule': '0 0 * * *'
            }
            
            return jsonify({
                'success': True,
                'pipeline': pipeline_data
            })
        else:
            return jsonify({
                'success': False,
                'error': f'Pipeline {pipeline_id} not found'
            }), 404
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pipeline/<pipeline_id>', methods=['PUT'])
def update_pipeline(pipeline_id):
    """Update a pipeline"""
    try:
        data = request.get_json()
        
        # Mock implementation - in real system this would update database
        return jsonify({
            'success': True,
            'message': f'Pipeline {pipeline_id} updated successfully'
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/pipeline/<pipeline_id>')
def view_pipeline(pipeline_id):
    """View individual pipeline details"""
    try:
        # For now, only support the existing stavanger_parking pipeline
        if pipeline_id == 'stavanger_parking':
            pipeline_data = {
                'id': 'stavanger_parking',
                'name': 'Stavanger Parking',
                'type': 'dbt',
                'description': 'Real-time parking utilization insights and business intelligence',
                'project_dir': 'dbt_stavanger_parking',
                'target': 'dev',
                'schedule': '0 0 * * *'
            }
            
            # Get pipeline status and metrics
            status_data = get_pipeline_status_data()
            metrics_data = get_pipeline_metrics()
            
            return render_template('pipeline.html', 
                                 pipeline=pipeline_data,
                                 pipeline_status=status_data,
                                 pipeline_metrics=metrics_data)
        else:
            return "Pipeline not found", 404
            
    except Exception as e:
        return f"Error loading pipeline: {str(e)}", 500

def get_pipeline_status_data():
    """Get pipeline status data for the existing stavanger_parking pipeline"""
    try:
        # Get actual pipeline metrics
        metrics = get_pipeline_metrics()
        
        return {
            'status': 'running',
            'last_run': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'models_count': 5,
            'tests_passed': 3,
            'data_quality': 'good',
            'critical_alerts': 0,
            'total_records': metrics.get('total_records', 0),
            'total_locations': metrics.get('locations_monitored', 0)
        }
    except Exception as e:
        return {
            'status': 'unknown',
            'last_run': 'N/A',
            'models_count': 0,
            'tests_passed': 0,
            'data_quality': 'unknown',
            'critical_alerts': 0,
            'total_records': 0,
            'total_locations': 0
        }

def update_pipeline_timestamp(pipeline_id):
    """Update the last run timestamp for a pipeline"""
    try:
        # This would typically update a database or configuration file
        # For now, we'll just log the update
        current_time = time.strftime('%Y-%m-%d %H:%M:%S')
        print(f"Pipeline {pipeline_id} last run updated to: {current_time}")
        
        # Update the pipeline status data
        global pipeline_status_data
        if pipeline_id == 'stavanger_parking':
            pipeline_status_data['last_run'] = current_time
            
    except Exception as e:
        print(f"Error updating pipeline timestamp: {e}")

# New unified API endpoints
@app.route('/api/platform/status')
def get_platform_status():
    """Get comprehensive platform status"""
    return jsonify(platform_api.get_platform_status())

@app.route('/api/platform/catalog')
def get_data_catalog():
    """Get comprehensive data catalog"""
    return jsonify(platform_api.get_data_catalog())

@app.route('/api/platform/quality')
def get_data_quality():
    """Get data quality metrics"""
    catalog = request.args.get('catalog', 'iceberg')
    schema = request.args.get('schema', 'default')
    return jsonify(platform_api.get_data_quality_metrics(catalog, schema))

@app.route('/api/storage/buckets')
def list_storage_buckets():
    """List all storage buckets"""
    return jsonify(platform_api.storage.list_buckets())

@app.route('/api/storage/bucket/<bucket_name>/objects')
def list_bucket_objects(bucket_name):
    """List objects in a bucket"""
    prefix = request.args.get('prefix', '')
    return jsonify(platform_api.storage.list_objects(bucket_name, prefix))

@app.route('/api/storage/stats')
def get_storage_stats():
    """Get storage statistics"""
    return jsonify(platform_api.storage.get_storage_stats())

@app.route('/api/query/catalogs')
def get_query_catalogs():
    """Get available query catalogs"""
    return jsonify(platform_api.query.get_catalogs())

@app.route('/api/query/schemas/<catalog>')
def get_query_schemas(catalog):
    """Get schemas in a catalog"""
    return jsonify(platform_api.query.get_schemas(catalog))

@app.route('/api/query/tables/<catalog>/<schema>')
def get_query_tables(catalog, schema):
    """Get tables in a schema"""
    return jsonify(platform_api.query.get_tables(catalog, schema))

@app.route('/storage-management')
def storage_management():
    """Storage management page"""
    return render_template('storage_management.html')

@app.route('/api/storage/buckets', methods=['POST'])
def create_storage_bucket():
    """Create a new storage bucket"""
    try:
        data = request.get_json()
        bucket_name = data.get('name')
        
        if not bucket_name:
            return jsonify({'success': False, 'error': 'Bucket name is required'}), 400
        
        success = platform_api.storage.create_bucket(bucket_name)
        
        if success:
            return jsonify({'success': True, 'message': f'Bucket {bucket_name} created successfully'})
        else:
            return jsonify({'success': False, 'error': 'Failed to create bucket'}), 500
            
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/storage/bucket/<bucket_name>/objects/<path:object_key>', methods=['DELETE'])
def delete_storage_object(bucket_name, object_key):
    """Delete an object from storage"""
    try:
        success = platform_api.storage.delete_object(bucket_name, object_key)
        
        if success:
            return jsonify({'success': True, 'message': f'Object {object_key} deleted successfully'})
        else:
            return jsonify({'success': False, 'error': 'Failed to delete object'}), 500
            
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/storage/upload', methods=['POST'])
def upload_storage_file():
    """Upload a file to storage"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'No file provided'}), 400
        
        file = request.files['file']
        bucket_name = request.form.get('bucket')
        object_key = request.form.get('key', file.filename)
        
        if not bucket_name:
            return jsonify({'success': False, 'error': 'Bucket name is required'}), 400
        
        if file.filename == '':
            return jsonify({'success': False, 'error': 'No file selected'}), 400
        
        # Save file temporarily
        temp_path = f'/tmp/{file.filename}'
        file.save(temp_path)
        
        # Upload to storage
        success = platform_api.storage.upload_file(bucket_name, object_key, temp_path)
        
        # Clean up temp file
        try:
            os.remove(temp_path)
        except:
            pass
        
        if success:
            return jsonify({
                'success': True, 
                'message': f'File {file.filename} uploaded successfully',
                'location': f'{bucket_name}/{object_key}'
            })
        else:
            return jsonify({'success': False, 'error': 'Failed to upload file'}), 500
            
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/bi-dashboard')
def bi_dashboard():
    """Business Intelligence Dashboard"""
    return render_template('bi_dashboard.html')

@app.route('/api/ingestion/stats')
def get_ingestion_stats():
    """Get ingestion statistics"""
    return jsonify(ingestion_api.get_ingestion_stats())

@app.route('/api/ingestion/history')
def get_ingestion_history():
    """Get ingestion history"""
    limit = request.args.get('limit', 100, type=int)
    return jsonify(ingestion_api.get_ingestion_history(limit))

@app.route('/api/quality/run-checks')
def run_quality_checks():
    """Run data quality checks"""
    catalog = request.args.get('catalog', 'iceberg')
    schema = request.args.get('schema', 'default')
    return jsonify(quality_api.run_quality_checks(catalog, schema))

@app.route('/api/quality/metrics')
def get_quality_metrics():
    """Get data quality metrics"""
    try:
        from api.platform import platform_api
        metrics = platform_api.get_data_quality_metrics()
        return jsonify(metrics)
    except Exception as e:
        return jsonify({
            'error': f'Failed to get quality metrics: {str(e)}',
            'overall_score': 0.0,
            'checks_performed': 0
        }), 500

# Removed duplicate streaming-dashboard route - use /streaming instead

# Streaming API endpoints
@app.route('/api/streaming/status')
def get_streaming_status():
    """Get streaming platform status"""
    try:
        status = streaming_api.get_streaming_status()
        return jsonify(status)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/streaming/topics', methods=['POST'])
def create_streaming_topic():
    """Create a new Kafka topic"""
    try:
        data = request.get_json()
        topic_name = data.get('topic_name')
        config = data.get('config', {})
        
        if not topic_name:
            return jsonify({'error': 'Topic name is required'}), 400
        
        result = streaming_api.create_streaming_topic(topic_name, config)
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/streaming/pipelines', methods=['POST'])
def start_streaming_pipeline():
    """Start a streaming pipeline"""
    try:
        data = request.get_json()
        pipeline_name = data.get('pipeline_name')
        config = data.get('config', {})
        
        if not pipeline_name:
            return jsonify({'error': 'Pipeline name is required'}), 400
        
        result = streaming_api.start_streaming_pipeline(pipeline_name, config)
        return jsonify(result)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/streaming/metrics/<topic_name>')
def get_streaming_metrics(topic_name):
    """Get streaming metrics for a topic"""
    try:
        time_range = request.args.get('time_range', '1h')
        metrics = streaming_api.get_streaming_metrics(topic_name, time_range)
        return jsonify(metrics)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/platform/parking-metrics')
def get_parking_metrics():
    """Get Stavanger parking metrics"""
    try:
        # Get parking data from Trino
        from api.query import TrinoAPI
        trino_client = TrinoAPI()
        
        # Query for parking metrics
        query = """
        SELECT 
            COUNT(*) as total_records,
            AVG(occupancy_rate) as avg_occupancy,
            MAX(occupancy_rate) as max_occupancy,
            COUNT(DISTINCT parking_zone) as unique_zones,
            COUNT(DISTINCT DATE(timestamp)) as unique_dates
        FROM iceberg.default.stavanger_parking
        """
        
        results = trino_client.execute_query(query)
        if results and results[0]:
            row = results[0]
            return jsonify({
                'total_records': row[0] or 0,
                'avg_occupancy': round(row[1], 2) if row[1] else 0.0,
                'max_occupancy': round(row[2], 2) if row[2] else 0.0,
                'unique_zones': row[3] or 0,
                'unique_dates': row[4] or 0,
                'data_freshness': 'Real-time',
                'pipeline_health': 'Active'
            })
        else:
            # Fallback to sample data
            return jsonify({
                'total_records': 0,
                'avg_occupancy': 0.0,
                'max_occupancy': 0.0,
                'unique_zones': 0,
                'unique_dates': 0,
                'data_freshness': 'N/A',
                'pipeline_health': 'Unknown'
            })
            
    except Exception as e:
        print(f"Error getting parking metrics: {e}")
        return jsonify({
            'total_records': 0,
            'avg_occupancy': 0.0,
            'max_occupancy': 0.0,
            'unique_zones': 0,
            'unique_dates': 0,
            'data_freshness': 'Error',
            'pipeline_health': 'Error'
        }), 500

@app.route('/api/pipeline/list')
def get_pipeline_list():
    """Get list of all available pipelines"""
    try:
        # Get available pipelines from the dbt project
        dbt_project_dir = os.path.join(os.getcwd(), 'dbt_stavanger_parking')
        
        if os.path.exists(dbt_project_dir):
            pipelines = [
                {
                    'name': 'stavanger_parking',
                    'type': 'dbt',
                    'status': 'ready',
                    'last_run': get_last_pipeline_run('stavanger_parking'),
                    'next_run': None,  # Would come from scheduler
                    'description': 'Stavanger Parking Data Pipeline'
                }
            ]
        else:
            pipelines = []
        
        return jsonify({
            'success': True,
            'pipelines': pipelines
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pipeline/stats')
def get_pipeline_stats():
    """Get pipeline statistics"""
    try:
        # Count available pipelines
        dbt_project_dir = os.path.join(os.getcwd(), 'dbt_stavanger_parking')
        total_pipelines = 1 if os.path.exists(dbt_project_dir) else 0
        
        # Get pipeline statuses
        active_pipelines = 0
        failed_pipelines = 0
        success_rate = 1.0
        
        # Check if Stavanger parking pipeline exists and is working
        if total_pipelines > 0:
            try:
                # Check if dbt project is valid
                result = subprocess.run(
                    ['dbt', 'debug', '--project-dir', dbt_project_dir],
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                if result.returncode == 0:
                    active_pipelines = 1
                    failed_pipelines = 0
                    success_rate = 1.0
                else:
                    failed_pipelines = 1
                    success_rate = 0.0
            except Exception:
                failed_pipelines = 1
                success_rate = 0.0
        
        return jsonify({
            'success': True,
            'total_pipelines': total_pipelines,
            'active_pipelines': active_pipelines,
            'failed_pipelines': failed_pipelines,
            'success_rate': success_rate
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def get_last_pipeline_run(pipeline_name):
    """Get the last run timestamp for a pipeline"""
    try:
        # Check for dbt run artifacts
        dbt_project_dir = os.path.join(os.getcwd(), 'dbt_stavanger_parking')
        target_dir = os.path.join(dbt_project_dir, 'target')
        
        if os.path.exists(target_dir):
            # Look for run_results.json
            run_results_file = os.path.join(target_dir, 'run_results.json')
            if os.path.exists(run_results_file):
                with open(run_results_file, 'r') as f:
                    run_data = json.load(f)
                    if 'metadata' in run_data and 'generated_at' in run_data['metadata']:
                        return run_data['metadata']['generated_at']
        
        # Fallback to file modification time
        dbt_project_file = os.path.join(dbt_project_dir, 'dbt_project.yml')
        if os.path.exists(dbt_project_file):
            return datetime.fromtimestamp(os.path.getmtime(dbt_project_file)).isoformat()
        
        return None
    except Exception:
        return None

# Streaming API endpoints
@app.route('/api/streaming/topics')
def get_streaming_topics():
    """Get Kafka topic status and information"""
    try:
        # Get topics from Kafka
        topics = []
        
        # Raw data topic
        topics.append({
            'name': 'parking-raw-data',
            'status': 'healthy',
            'partitions': 3,
            'messages': get_topic_message_count('parking-raw-data'),
            'replicas': 1,
            'cleanup_policy': 'delete'
        })
        
        # Processed data topic
        topics.append({
            'name': 'parking-processed-data',
            'status': 'healthy',
            'partitions': 3,
            'messages': get_topic_message_count('parking-processed-data'),
            'replicas': 1,
            'cleanup_policy': 'delete'
        })
        
        # Alerts topic
        topics.append({
            'name': 'parking-alerts',
            'status': 'healthy',
            'partitions': 2,
            'messages': get_topic_message_count('parking-alerts'),
            'replicas': 1,
            'cleanup_policy': 'delete'
        })
        
        return jsonify(topics)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/streaming/consumers')
def get_streaming_consumers():
    """Get consumer group information and lag"""
    try:
        consumers = []
        
        # Simulate consumer groups (in real implementation, get from Kafka)
        consumers.append({
            'group': 'parking-processor',
            'topic': 'parking-raw-data',
            'lag': random.randint(0, 5),
            'status': 'active',
            'members': 2
        })
        
        consumers.append({
            'group': 'alert-processor',
            'topic': 'parking-processed-data',
            'lag': random.randint(0, 3),
            'status': 'active',
            'members': 1
        })
        
        consumers.append({
            'group': 'data-archiver',
            'topic': 'parking-processed-data',
            'lag': random.randint(5, 15),
            'status': 'active',
            'members': 1
        })
        
        return jsonify(consumers)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/streaming/live-data')
def get_live_streaming_data():
    """Get live streaming data for dashboard display"""
    try:
        # Get recent messages from topics (simulated for now)
        messages = []
        
        # Raw data messages
        raw_count = get_topic_message_count('parking-raw-data')
        if raw_count > 0:
            messages.append({
                'type': 'raw',
                'timestamp': datetime.now().isoformat(),
                'data': {
                    'location': 'Stavanger Sentrum',
                    'utilization_rate': random.randint(20, 80),
                    'available_spaces': random.randint(10, 50),
                    'timestamp': datetime.now().isoformat()
                }
            })
        
        # Processed data messages
        processed_count = get_topic_message_count('parking-processed-data')
        if processed_count > 0:
            messages.append({
                'type': 'processed',
                'timestamp': datetime.now().isoformat(),
                'data': {
                    'location': 'Stavanger Sentrum',
                    'utilization_rate': random.randint(20, 80),
                    'available_spaces': random.randint(10, 50),
                    'processed_at': datetime.now().isoformat(),
                    'processing_latency_ms': random.randint(10, 100)
                }
            })
        
        # Alert messages
        alert_count = get_topic_message_count('parking-alerts')
        if alert_count > 0:
            messages.append({
                'type': 'alert',
                'timestamp': datetime.now().isoformat(),
                'data': {
                    'alert_type': 'HIGH_UTILIZATION',
                    'location': 'Stavanger Sentrum',
                    'severity': 'WARNING',
                    'utilization_rate': random.randint(85, 95)
                }
            })
        
        return jsonify({
            'messages': messages,
            'counts': {
                'raw': raw_count,
                'processed': processed_count,
                'alerts': alert_count
            },
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/streaming/start', methods=['POST'])
def start_streaming():
    """Start streaming data generation"""
    try:
        # In a real implementation, this would start the streaming job
        # For now, we'll just return success
        return jsonify({'status': 'success', 'message': 'Streaming started'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/streaming/stop', methods=['POST'])
def stop_streaming():
    """Stop streaming data generation"""
    try:
        # In a real implementation, this would stop the streaming job
        # For now, we'll just return success
        return jsonify({'status': 'success', 'message': 'Streaming stopped'})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def get_topic_message_count(topic_name):
    """Get message count for a specific topic"""
    try:
        # In a real implementation, this would query Kafka directly
        # For now, return simulated counts
        base_counts = {
            'parking-raw-data': 150,
            'parking-processed-data': 145,
            'parking-alerts': 25
        }
        
        # Add some randomness to simulate live data
        base_count = base_counts.get(topic_name, 0)
        return base_count + random.randint(0, 10)
    except:
        return 0

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000, debug=True)
